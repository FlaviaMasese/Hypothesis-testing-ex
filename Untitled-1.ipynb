{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flavia's fast food chain Data Analysis.\n",
    "My task is to detrmine the best promotion that can increase sales with an introduction of a new item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking up the data!\n",
    "The first step in this is figuring out what we need to clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MarketID</th>\n",
       "      <th>MarketSize</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>AgeOfStore</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>week</th>\n",
       "      <th>SalesInThousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>39.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>10</td>\n",
       "      <td>Large</td>\n",
       "      <td>919</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>64.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>10</td>\n",
       "      <td>Large</td>\n",
       "      <td>920</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>10</td>\n",
       "      <td>Large</td>\n",
       "      <td>920</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>45.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>10</td>\n",
       "      <td>Large</td>\n",
       "      <td>920</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>44.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>10</td>\n",
       "      <td>Large</td>\n",
       "      <td>920</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>49.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MarketID MarketSize  LocationID  AgeOfStore  Promotion  week  \\\n",
       "0           1     Medium           1           4          3     1   \n",
       "1           1     Medium           1           4          3     2   \n",
       "2           1     Medium           1           4          3     3   \n",
       "3           1     Medium           1           4          3     4   \n",
       "4           1     Medium           2           5          2     1   \n",
       "..        ...        ...         ...         ...        ...   ...   \n",
       "543        10      Large         919           2          1     4   \n",
       "544        10      Large         920          14          2     1   \n",
       "545        10      Large         920          14          2     2   \n",
       "546        10      Large         920          14          2     3   \n",
       "547        10      Large         920          14          2     4   \n",
       "\n",
       "     SalesInThousands  \n",
       "0               33.73  \n",
       "1               35.67  \n",
       "2               29.03  \n",
       "3               39.25  \n",
       "4               27.81  \n",
       "..                ...  \n",
       "543             64.34  \n",
       "544             50.20  \n",
       "545             45.75  \n",
       "546             44.29  \n",
       "547             49.41  \n",
       "\n",
       "[548 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketing_data= pd.read_csv(r'C:\\Users\\flavi\\OneDrive\\Desktop\\data for practice\\Marketing.csv')\n",
    "marketing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarketID            0\n",
       "MarketSize          0\n",
       "LocationID          0\n",
       "AgeOfStore          0\n",
       "Promotion           0\n",
       "week                0\n",
       "SalesInThousands    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketing_data.Promotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketing_data.MarketID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Medium', 'Small', 'Large'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketing_data.MarketSize.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'm going to look at the differences in sales based on weekly bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "week\n",
       "1    53.790584\n",
       "2    53.386569\n",
       "3    53.474599\n",
       "4    53.213066\n",
       "Name: SalesInThousands, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketing_data.groupby(['week'])['SalesInThousands'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am first going to test test the assumptions to see whether the data meets the assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols #for n-way ANOVA\n",
    "from statsmodels.stats.anova import _get_covariance,anova_lm #for n-way ANOVA\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd #for performing the Tukey-HSD test\n",
    "from statsmodels.stats.multicomp import MultiComparison #To compare the levels of independent Var & dependent Var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform one-way ANOVA where your categorical variable is Week and continous variable is SalesInThousands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_data['Week'] = marketing_data['week'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    137\n",
       "2    137\n",
       "3    137\n",
       "4    137\n",
       "Name: week, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketing_data['week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             df         sum_sq     mean_sq         F    PR(>F)\n",
      "week        1.0      18.525580   18.525580  0.065876  0.797535\n",
      "Residual  546.0  153544.754125  281.217498       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "formula = 'SalesInThousands ~ (week)'\n",
    "model = ols(formula, marketing_data).fit()\n",
    "aov_table = anova_lm(model)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant relationship in sales based on week since p value is less than 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did a tukeyhsd test to further verify the significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "     1      2   -0.404 0.9972 -5.6349 4.8269  False\n",
      "     1      3   -0.316 0.9987 -5.5469 4.9149  False\n",
      "     1      4  -0.5775  0.992 -5.8084 4.6534  False\n",
      "     2      3    0.088    1.0 -5.1429 5.3189  False\n",
      "     2      4  -0.1735 0.9998 -5.4044 5.0574  False\n",
      "     3      4  -0.2615 0.9992 -5.4924 4.9694  False\n",
      "---------------------------------------------------\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "mc = MultiComparison(marketing_data['SalesInThousands'], marketing_data['week'])\n",
    "result = mc.tukeyhsd()\n",
    "\n",
    "print(result)\n",
    "print(mc.groupsunique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2:Checking for Linearity\n",
    "Before you execute a linear regression model, it is advisable to validate that certain assumptions are met.\n",
    "you may want to check that a linear relationship exists between the dependent variable and the independent variable/s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a multilinear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>SalesInThousands</td> <th>  R-squared:         </th> <td>   0.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   135.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 23 Aug 2022</td> <th>  Prob (F-statistic):</th> <td>5.22e-80</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:43:10</td>     <th>  Log-Likelihood:    </th> <td> -2132.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   548</td>      <th>  AIC:               </th> <td>   4275.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   543</td>      <th>  BIC:               </th> <td>   4297.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>   70.1805</td> <td>    1.611</td> <td>   43.562</td> <td> 0.000</td> <td>   67.016</td> <td>   73.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(MarketSize)[T.Medium]</th> <td>  -26.2576</td> <td>    1.143</td> <td>  -22.965</td> <td> 0.000</td> <td>  -28.503</td> <td>  -24.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(MarketSize)[T.Small]</th>  <td>  -13.0421</td> <td>    1.814</td> <td>   -7.189</td> <td> 0.000</td> <td>  -16.606</td> <td>   -9.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AgeOfStore</th>              <td>    0.1045</td> <td>    0.078</td> <td>    1.342</td> <td> 0.180</td> <td>   -0.048</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Promotion</th>               <td>   -0.4150</td> <td>    0.630</td> <td>   -0.659</td> <td> 0.510</td> <td>   -1.653</td> <td>    0.823</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.836</td> <th>  Durbin-Watson:     </th> <td>   0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.033</td> <th>  Jarque-Bera (JB):  </th> <td>   5.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.164</td> <th>  Prob(JB):          </th> <td>  0.0590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.626</td> <th>  Cond. No.          </th> <td>    43.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       SalesInThousands   R-squared:                       0.499\n",
       "Model:                            OLS   Adj. R-squared:                  0.495\n",
       "Method:                 Least Squares   F-statistic:                     135.0\n",
       "Date:                Tue, 23 Aug 2022   Prob (F-statistic):           5.22e-80\n",
       "Time:                        16:43:10   Log-Likelihood:                -2132.5\n",
       "No. Observations:                 548   AIC:                             4275.\n",
       "Df Residuals:                     543   BIC:                             4297.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                  70.1805      1.611     43.562      0.000      67.016      73.345\n",
       "C(MarketSize)[T.Medium]   -26.2576      1.143    -22.965      0.000     -28.503     -24.012\n",
       "C(MarketSize)[T.Small]    -13.0421      1.814     -7.189      0.000     -16.606      -9.479\n",
       "AgeOfStore                  0.1045      0.078      1.342      0.180      -0.048       0.257\n",
       "Promotion                  -0.4150      0.630     -0.659      0.510      -1.653       0.823\n",
       "==============================================================================\n",
       "Omnibus:                        6.836   Durbin-Watson:                   0.515\n",
       "Prob(Omnibus):                  0.033   Jarque-Bera (JB):                5.661\n",
       "Skew:                          -0.164   Prob(JB):                       0.0590\n",
       "Kurtosis:                       2.626   Cond. No.                         43.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit = ols('SalesInThousands ~ AgeOfStore + C(MarketSize) + Promotion', data=marketing_data).fit() \n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, chi2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state hypotheses & set acceptance criteria\n",
    "null_hypothesis = \"There is no relationship between promotion and sales. They are independent.\"\n",
    "alternate_hypothesis = \"There is a relationship promotion and sales. They are not independent.\"\n",
    "acceptance_criteria = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_values = pd.crosstab(marketing_data[\"Promotion\"], marketing_data[\"SalesInThousands\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SalesInThousands ~ C(week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031.352630710869 0.4998311555493914\n",
      "1090.6339511955696\n"
     ]
    }
   ],
   "source": [
    "# calculate expected frequencies & chi square statistic\n",
    "chi2_statistic, p_value, dof, expected_values = chi2_contingency(observed_values, correction = False)\n",
    "print(chi2_statistic, p_value)\n",
    "\n",
    "# find the critical value for our test\n",
    "critical_value = chi2.ppf(1 - acceptance_criteria, dof)\n",
    "print(critical_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess parameters to make them ready for the z-score test\n",
    "def preprocess(experiment, control):\n",
    "    mean_one = experiment[\"converted\"].mean()\n",
    "    sum_one = experiment[\"converted\"].std()\n",
    "    count_one = experiment[\"converted\"].count()\n",
    "    \n",
    "    mean_two = control[\"converted\"].mean()\n",
    "    sum_two = control[\"converted\"].std()\n",
    "    count_two = control[\"converted\"].count()\n",
    "    \n",
    "    return [mean_one, sum_one, count_one], [mean_two, sum_two, count_two]\n",
    "\n",
    "# Calculate the z-scores on the experiment and control groups\n",
    "def zscore_test(experiment, control, val=0):\n",
    "    \n",
    "    exp, ctrl = preprocess(experiment, control)\n",
    "    \n",
    "    return (exp[0] - ctrl[0] - val)/(np.sqrt(exp[1]**2/exp[2] + ctrl[1]**2/ctrl[2]))\n",
    "\n",
    "# Calculate lower bound of confidence intervals for the test\n",
    "def confidence(experiment, control, Z):\n",
    "    exp, ctrl = preprocess(experiment, control)\n",
    "    lower_interval = (exp[0] - ctrl[0]) - Z * (np.sqrt(exp[1]**2/exp[2] + ctrl[1]**2/ctrl[2]))\n",
    "    return lower_interval\n",
    "\n",
    "# Calculate the z-score's alpha value to reject null hypothesis\n",
    "z_alpha = norm.ppf(1-alpha)\n",
    "print(\"z_alpha: {}\".format(z_alpha))\n",
    "results[('converted', 'z_score')] = \"\"\n",
    "\n",
    "group_ctrl = groups.get_group((\"no\", \"no\"))\n",
    "\n",
    "for key in list(groups.groups.keys())[1:]:\n",
    "    group_exp = groups.get_group(key)\n",
    "    zscore = do_zscore(group_exp, group_ctrl)\n",
    "    results.loc[key, ('converted', 'z_score')] = zscore   \n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the significance level for acceptance\n",
    "alpha = 0.05\n",
    "\n",
    "# Cohen's d is an effect size used to indicate the standardised difference between two means.\n",
    "def cohen_d(param_one, param_two):\n",
    "    std = np.sqrt((np.std(param_one)**2 + np.std(param_two)**2)/2)\n",
    "    mean = np.mean(param_two) - np.mean(param_one)\n",
    "    return np.abs(mean/std)\n",
    "\n",
    "# Power analysis\n",
    "def do_power(param_one, param_two, alpha, num_obs=10121, ratio=1.0, alternative='larger'):\n",
    "    effect_size = cohen_d(param_one,param_two)\n",
    "    return NormalIndPower().power(effect_size=effect_size, nobs1 = num_obs, alpha=alpha,\n",
    "                                  ratio=ratio, alternative=alternative)\n",
    "\n",
    "results[('converted', 'power_score')] = \"\"\n",
    "\n",
    "group_ctrl = groups.get_group((\"no\", \"no\"))\n",
    "\n",
    "for key in list(groups.groups.keys())[1:]:\n",
    "    group_exp = groups.get_group(key)\n",
    "    power = do_power(group_ctrl['converted'], group_exp['converted'], alpha)\n",
    "    summary.loc[key, ('converted', 'power_score')] = power   \n",
    "    \n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b46fdcec2a339de20233c8d89095cb8b913f8f11208c0db25baf66f440175c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
